{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349c96a5-b4d8-4768-a6bc-99575b1b849d",
   "metadata": {},
   "source": [
    "# Explore the effects of tumor purity on ecDNA annotations.\n",
    "**Please remember not to commit data or visualizations to GitHub!**\n",
    "\n",
    "Best way to do this is to clear outputs of all cells before saving and committing changes to a notebook, and to make good use of the .gitignore file.\n",
    "\n",
    "## Requirements\n",
    "Data:\n",
    "- `../data/cloud/opentarget/histologies.tsv` (get this file from OneDrive/2023-pedpancan/data/opentarget/histologies.tsv)\n",
    "\n",
    "Software:\n",
    "- pandas\n",
    "- numpy\n",
    "- seaborn\n",
    "- scipy\n",
    "- sklearn\n",
    "\n",
    "## Results\n",
    "- Logistic regression figure saved to `out/TODO`\n",
    "- Tumor purity has nonsignificant effect on ecDNA prediction (likelihood ratio test, p=0.20, comparing models with covariates for sex, age, tumor type and extent of resection on n=1020 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782d026-863e-46dc-b2b3-5b25aa8f830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../src')\n",
    "Path(\"out\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import data_imports\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f2918-39a1-43e8-9df4-2f15a9c41014",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', '.*differs between CAVATICA and opentarget annotations.*')\n",
    "df = data_imports.generate_cbtn_biosample_table(verbose=1)\n",
    "df = data_imports.unify_tumor_diagnoses(df,include_HM=False)\n",
    "df = data_imports.clean_tumor_diagnoses(df)\n",
    "df = data_imports.annotate_with_ecDNA(df)\n",
    "df = data_imports.annotate_amplicon_class(df)\n",
    "df = data_imports.annotate_duplicate_biosamples(df)\n",
    "warnings.resetwarnings()\n",
    "df=df[df.in_unique_patient_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b20d7-7a88-4bd9-a475-31fb6e8e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6b288-b02b-4fb8-900b-4421941e9187",
   "metadata": {},
   "source": [
    "## Tumor fraction metrics metaanalysis\n",
    "OpenPBTA has 4 (four!) annotations for tumor fraction:\n",
    "- tumor_fraction (Theta2, from WGS)\n",
    "- tumor_fraction_RFpurify_ABSOLUTE (random forest predicting ABSOLUTE estimates (SNP array))\n",
    "- tumor_fraction_RFpurify_ESTIMATE (random forest predicting ESTIMATE estimates (RNA-seq or affy array))\n",
    "- tumor_fraction_LUMP (from leukocyte-specific CpGs in 450k array)\n",
    "\n",
    "We're going to use Theta2 for downstream analyses but it's useful to know how well these estimates agree with each other.\n",
    "\n",
    "### TODO:\n",
    "- report how complete these annotations are (of our cohort, how many have annotations for each of these metrics?)\n",
    "- report pairwise Pearson's R between these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc388f-1b69-446b-952a-7358332729d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8845d4-03c6-47c5-933c-8a6bb652258b",
   "metadata": {},
   "source": [
    "## Association with ecDNA\n",
    "\n",
    "### TODO\n",
    "- plot ecDNA as a function of tumor_purity using [seaborn regplot](https://seaborn.pydata.org/generated/seaborn.regplot.html)\n",
    "### Done\n",
    "- likelihood ratio test to see if adding tumor_purity significantly improves the model.\n",
    "  https://www.statology.org/likelihood-ratio-test-in-python/  \n",
    "  p = np.float64(0.20063803277943237), n=1020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9e185-a978-426f-a94d-fadd72a2fa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2017 Ronald J. Nowling\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "def likelihood_ratio_test(features_alternate, labels, lr_model, features_null=None):\n",
    "    \"\"\"\n",
    "    Compute the likelihood ratio test for a model trained on the set of features in\n",
    "    `features_alternate` vs a null model.  If `features_null` is not defined, then\n",
    "    the null model simply uses the intercept (class probabilities).  Note that\n",
    "    `features_null` must be a subset of `features_alternative` -- it can not contain\n",
    "    features that are not in `features_alternate`.\n",
    "    Returns the p-value, which can be used to accept or reject the null hypothesis.\n",
    "    \"\"\"\n",
    "    labels = np.array(labels)\n",
    "    features_alternate = np.array(features_alternate)\n",
    "    \n",
    "    if features_null is not None:\n",
    "        features_null = np.array(features_null)\n",
    "        \n",
    "        if features_null.shape[1] >= features_alternate.shape[1]:\n",
    "            raise ValueError(\"Alternate features must have more features than null features\")\n",
    "        \n",
    "        lr_model.fit(features_null, labels)\n",
    "        null_prob = lr_model.predict_proba(features_null)#[:, 1]\n",
    "        df = features_alternate.shape[1] - features_null.shape[1]\n",
    "    else:\n",
    "        null_prob = sum(labels) / float(labels.shape[0]) * \\\n",
    "                    np.ones(labels.shape)\n",
    "        df = features_alternate.shape[1]\n",
    "    \n",
    "    lr_model.fit(features_alternate, labels)\n",
    "    alt_prob = lr_model.predict_proba(features_alternate)\n",
    "\n",
    "    alt_log_likelihood = -log_loss(labels,\n",
    "                                   alt_prob,\n",
    "                                   normalize=False)\n",
    "    null_log_likelihood = -log_loss(labels,\n",
    "                                    null_prob,\n",
    "                                    normalize=False)\n",
    "\n",
    "    G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "    p_value = chi2.sf(G, df)\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1613185-871b-4d45-932f-9223973d0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "v1 = ['sex','age_at_diagnosis','extent_of_tumor_resection','cancer_type']\n",
    "v2 = v1 + ['tumor_fraction']\n",
    "data = df[v2+['amplicon_class']].dropna()\n",
    "# drop rare values\n",
    "cts = data.extent_of_tumor_resection.value_counts()\n",
    "keep = cts[cts >=5].index\n",
    "data = data[data.extent_of_tumor_resection.isin(keep)]\n",
    "keep=['LGG','CPG','CPT','EMBT','EPN','ETMR','GCT','HGG','MBL','NBL','PINT']\n",
    "#keep=['CPT','EPN','GCT','HGG','MBL','NBL','PINT']\n",
    "data=data[data.cancer_type.isin(keep)]\n",
    "\n",
    "# data definitions\n",
    "y = data.amplicon_class\n",
    "x1=pd.get_dummies(data[v1])\n",
    "x2=pd.get_dummies(data[v2])\n",
    "\n",
    "# models\n",
    "model = LogisticRegression(penalty=None,solver='newton-cg')\n",
    "\n",
    "likelihood_ratio_test(features_alternate=x2,features_null=x1,lr_model=model,labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddb311-c2f4-4b1d-b257-15bdee2618ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9f0b8-7fec-406b-92c6-55ab3cf06599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
