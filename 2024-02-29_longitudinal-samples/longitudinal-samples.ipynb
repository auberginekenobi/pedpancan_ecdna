{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afc63ac-2c0d-4d2b-95fd-7dc63a3be3fa",
   "metadata": {},
   "source": [
    "# Primaries, relapses and longitudinal pairs\n",
    "\n",
    "Sunita's and my counts for primary and secondary tumors are largely similar. However, my count\n",
    "of longitudinal samples is about half Sunita's. \n",
    "The reason for this seems to be that she is including Autopsy samples in pairs, and secondary/secondary pairs. Open question whether this is desired behavior. Certainly makes it more confusing to describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2e3c0-7b16-4922-8b3e-9aa89568e3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4d504-f863-4857-a6fb-30bea69a3a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BIOSAMPLES = data_imports.import_biosamples()\n",
    "# BIOSAMPLES.head()\n",
    "# BIOSAMPLES.tumor_history.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617a90f-366e-4ed3-9f46-f1ddf70193eb",
   "metadata": {},
   "source": [
    "# Count primary and secondary tumors with ecDNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883ed08-3cea-45b2-9904-66738e0678e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many diagnosis tumors have ecDNA? 126 / 1291\n",
    "# Update 11/2024: 210 / 2558\n",
    "def primaries_w_ecDNA(tumor_types=None,verbose=True):\n",
    "    if tumor_types == None:\n",
    "        df1 = BIOSAMPLES[BIOSAMPLES.tumor_history == \"Diagnosis\"].groupby('patient_id').agg(aggregated_value=('amplicon_class', lambda x: (x == 'ecDNA').sum())).reset_index()\n",
    "    else:\n",
    "        df1 = BIOSAMPLES[(BIOSAMPLES.tumor_history == \"Diagnosis\") & (BIOSAMPLES.cancer_type.isin(tumor_types))].groupby('patient_id').agg(aggregated_value=('amplicon_class', lambda x: (x == 'ecDNA').sum())).reset_index()\n",
    "    df1[\"primary_ecDNA\"] = df1.aggregated_value > 0\n",
    "    df1.set_index(\"patient_id\",inplace=True)\n",
    "    df1.drop(\"aggregated_value\",axis=1,inplace=True)\n",
    "    a = len(df1[df1.primary_ecDNA])\n",
    "    b = len(df1)\n",
    "    if verbose:\n",
    "        print(f\"{a} of {b} ({round(a/b*100,1)}%) primary tumors have ecDNA\")\n",
    "    return(df1)\n",
    "p = primaries_w_ecDNA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70612a4-ab20-4f44-a1f4-52b7dbaea3d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many secondary tumors have ecDNA? 33 / 199\n",
    "# Update 11/2024: 57 / 511\n",
    "def secondaries_w_ecDNA(verbose=True):\n",
    "    df2 = BIOSAMPLES[BIOSAMPLES.tumor_history.isin([\"Recurrence\",\"Progressive\",\"Relapse\",\"Metastasis\"])].groupby('patient_id').agg(aggregated_value=('amplicon_class', lambda x: (x == 'ecDNA').sum())).reset_index()\n",
    "    df2[\"secondary_ecDNA\"] = df2.aggregated_value > 0\n",
    "    df2.set_index(\"patient_id\",inplace=True)\n",
    "    df2.drop(\"aggregated_value\",axis=1,inplace=True)\n",
    "    a = len(df2[df2.secondary_ecDNA])\n",
    "    b = len(df2)\n",
    "    if verbose:\n",
    "        print(f\"{a} of {b} ({round(a/b*100,1)}%) secondary tumors have ecDNA\")\n",
    "    return(df2)\n",
    "s = secondaries_w_ecDNA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4e87a-03a4-4698-8aee-2c6f2bb5632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_primary_secondary_independence(p,s):\n",
    "    '''\n",
    "    Run a chi-sq test to test for association between primary/secondary\n",
    "    and ecDNA. Note that for the test to be valid, we can't have paired\n",
    "    samples so we throw out primary tumors also in the secondary set. \n",
    "    '''\n",
    "    s = s[~s.index.isin(p.index)]\n",
    "    a = p.primary_ecDNA.sum()\n",
    "    b = len(p) - a\n",
    "    c = s.secondary_ecDNA.sum()\n",
    "    d = len(s) - c\n",
    "    tbl = [[a,b],[c,d]]\n",
    "    return scipy.stats.chi2_contingency(tbl)\n",
    "test_primary_secondary_independence(p,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3db6e-0922-4406-a276-9f1d7e99af70",
   "metadata": {},
   "source": [
    "# Longitudinal tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e440e0-8031-4e05-891c-23bd5d11ef3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# longitudinal samples\n",
    "def get_longitudinal_primary_secondary_pairs(verbose=True):\n",
    "    df1 = primaries_w_ecDNA(verbose=False)\n",
    "    df2 = secondaries_w_ecDNA(False)\n",
    "    df=df1.merge(df2,how='inner',left_index=True,right_index=True)\n",
    "    if verbose:\n",
    "        print(f'{len(df)} primary/secondary pairs')\n",
    "    return df\n",
    "get_longitudinal_primary_secondary_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d610a3-3377-4ddf-af91-7ff3fae905bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5)\n",
    "SECONDARIES = ['Diagnosis','Progressive','Autopsy','Recurrence','Relapse','Metastasis'] #exclude second malignancies, no sample, unavailable\n",
    "def get_sj_pairs():\n",
    "    '''\n",
    "    We define a longitudinal case from SJ or PNOC which has a diagnosis sample and a non-diagnosis sample.\n",
    "    '''\n",
    "    df = BIOSAMPLES[(BIOSAMPLES.cohort.str.startswith(\"SJ\") | (BIOSAMPLES.cohort == \"PNOC\")) &\n",
    "                    (BIOSAMPLES.duplicated('patient_id',keep=False))]\n",
    "    grp = df.groupby('patient_id').filter(lambda x: x['tumor_history'].nunique() >= 2).sort_values([\"patient_id\",\"tumor_history\"])\n",
    "    return grp\n",
    "def get_cbtn_pairs():\n",
    "    '''\n",
    "    We define a longitudinal case from CBTN which has samples with different dates of diagnosis.\n",
    "    '''\n",
    "    df = BIOSAMPLES[BIOSAMPLES.cohort.isin([\"PBTA-X00\",\"PBTA-X01\"]) &\n",
    "                    (BIOSAMPLES.tumor_history.isin(SECONDARIES)) &\n",
    "                    (BIOSAMPLES.duplicated('patient_id',keep=False))]\n",
    "    grp = df.groupby('patient_id').filter(lambda x: x['age_at_diagnosis'].max()-x['age_at_diagnosis'].min()>=30).sort_values([\"patient_id\",\"age_at_diagnosis\"])\n",
    "    return grp\n",
    "def get_longitudinal_cases(verbose=True):\n",
    "    df = pd.concat([get_cbtn_pairs(),get_sj_pairs()])\n",
    "    if verbose:\n",
    "        a = df.patient_id.nunique()\n",
    "        b = df[df.amplicon_class == 'ecDNA'].patient_id.nunique()\n",
    "        print(f\"{b} of {a} longitudinal cases have ecDNA\")\n",
    "    return df\n",
    "\n",
    "#get_sj_pairs()\n",
    "#get_cbtn_pairs()\n",
    "longitudinal_cases = get_longitudinal_cases()\n",
    "longitudinal_cases\n",
    "# 5/2024: 18 of 85 longitudinal cases have ecDNA\n",
    "# 9/2024: 31 of 213 longitudinal cases have ecDNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72435713-3b6d-42f8-8171-5e6e943c219c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "longitudinal_cases[longitudinal_cases.amplicon_class=='ecDNA'].patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22857b16-310d-4a33-bbb9-8d5b02d643d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "longitudinal_cases.to_excel(\"out/longitudinal_cases.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30d6ab-8eb8-4a97-84a6-f46989ff4007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_suppl_tbl_7():\n",
    "    return pd.read_excel(data_imports.SUPPLEMENTARY_TABLES_PATH,sheet_name=\"7. Paired biosamples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e8c89-edc9-4312-88f4-f3664ffddf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_suppl_tbl_7()\n",
    "df.groupby('evolution_class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962fe96-771d-463b-b1be-968e3aad747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longitudinal_tumors_with_multi_ecDNA():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c00dd8ee-e836-456c-a9d3-1623c543e4be",
   "metadata": {},
   "source": [
    "## Notes on tumors with multiple ecDNAs\n",
    "- PT_7WYPEC3Q (SHH MBL, primary -> progressive)\n",
    "  - (loss) chr17p11.2, CN 15 \n",
    "  - (loss) chr17:28,683,354-29,500,780 (chr17q), CN 14\n",
    "  - (gain) TERT, CN 26\n",
    "  - (gain) PPM1D, CN 13\n",
    "- PT_KTRJ8TFY (H3K27 DMG, primary -> progressive)\n",
    "  - (gain) PICALM, CN 6\n",
    "  - (gain) FLT3 2x / CDX2, CN 15\n",
    "- PT_XA98HG1C (SHH MBL, primary -> progressive)\n",
    "  - (gain) MYCN, CN 54\n",
    "  - (loss) FHL2 partial, CN 7\n",
    "  - (recombinant) CCND2 partial, CN 15 -> 118\n",
    "- SJ004912 (OST, primary -> metastasis)\n",
    "  - (loss) amp6 no oncogenes, CN 12\n",
    "  - (loss) amp9 chr7 no oncogenes, only LOC124901577, CN 2\n",
    "  - (loss) amp10, probable FP\n",
    "- SJ000912\n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b35a5-f1c4-48d6-8381-b70dd6e81182",
   "metadata": {},
   "source": [
    "# AmpliconSimilarity Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca099c3-b218-4a8a-9247-ad186986f90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: these samples still need longitudinal analyses done.\n",
    "def get_ampliconsimilarity_todos():\n",
    "    df = get_suppl_tbl_7()\n",
    "    a = set(df.patient_id)\n",
    "    df = get_longitudinal_cases(False)\n",
    "    b = set(df[df.amplicon_class=='ecDNA'].patient_id)\n",
    "    return df[(~df.patient_id.isin(a)) & df.patient_id.isin(b)]\n",
    "pd.set_option('display.max_rows', None)\n",
    "get_ampliconsimilarity_todos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b131a-c538-4c11-8eff-99bcf6bc9e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate required input file for ampliconsimilarity: features_to_graph.txt file of the biosamples for longitudinal cases.\n",
    "\n",
    "def get_features_to_graph(file='../data/source/AmpliconClassifier/pedpancan_features_to_graph.txt'):\n",
    "    df = pd.read_csv(file,sep='\\t',header=None,names=['bed','graph'])\n",
    "    return df\n",
    "def subset_features_to_graph(pairs_df):\n",
    "    #pairs_df = get_longitudinal_cases(verbose=False)\n",
    "    ftg_df = get_features_to_graph()\n",
    "    for pt in pairs_df.patient_id.unique():\n",
    "        print(pt)\n",
    "        bs_set = pairs_df[pairs_df.patient_id == pt].index\n",
    "        ftg_subset = ftg_df[ftg_df.bed.str.contains('|'.join(bs_set))]\n",
    "        if len(ftg_subset) > 1:\n",
    "            print(\"cp2\")\n",
    "            filepath=f'out/{pt}_features_to_graph.txt'\n",
    "            ftg_subset.to_csv(filepath,sep='\\t',header=False,index=False)\n",
    "        else:\n",
    "            print(\"cp3\")\n",
    "            continue\n",
    "    return\n",
    "subset_features_to_graph(get_ampliconsimilarity_todos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58563fd8-f415-4bd0-9161-d0a71d32a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ampliconsimilarity_todos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae41f15-9d51-459a-aa7c-2219e5828d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6afa64-bd44-4aa4-9aa8-74a9cb6bc0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse output\n",
    "\n",
    "def get_feature_similarity_scores(file=\"../data/source/AmpliconClassifier/pedpancan_feature_similarity_scores.tsv\"):\n",
    "    df = pd.read_csv(file,sep='\\t')\n",
    "    return df\n",
    "df = get_feature_similarity_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc117c-33dc-40da-beb5-e2d57db35a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca9c41-c0bb-4faa-b063-b3ad11339f04",
   "metadata": {},
   "source": [
    "# AmpliconSimilarity outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac878c62-ed6e-4e59-9e68-d924dfb5ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AS outputs\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Breakpoint(object):\n",
    "    def __init__(self, lchrom, lpos, lstrand, rchrom, rpos, rstrand, cn):\n",
    "        self.lchrom = lchrom\n",
    "        self.lpos = int(lpos)\n",
    "        self.lstrand = lstrand\n",
    "        self.rchrom = rchrom\n",
    "        self.rpos = int(rpos)\n",
    "        self.rstrand = rstrand\n",
    "        self.cn = cn\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.lchrom}:{str(self.lpos)}{'+' if self.lstrand else '-'}|{self.rchrom}:{str(self.rpos)}{'+' if self.rstrand else '-'}\"\n",
    "\n",
    "    def d_similar(self, bp2, d):\n",
    "        bp2_chrom_set = {bp2.lchrom, bp2.rchrom}\n",
    "        if self.lchrom not in bp2_chrom_set or self.rchrom not in bp2_chrom_set:\n",
    "            return False\n",
    "\n",
    "        sbp1 = sorted([(self.lchrom, self.lpos, self.lstrand), (self.rchrom, self.rpos, self.rstrand)])\n",
    "        sbp2 = sorted([(bp2.lchrom, bp2.lpos, bp2.lstrand), (bp2.rchrom, bp2.rpos, bp2.rstrand)])\n",
    "        \n",
    "        # if chromosomes and strands are the same\n",
    "        if sbp1[0][0] == sbp2[0][0] and sbp1[1][0] == sbp2[1][0] and sbp1[0][2] == sbp2[0][2] and sbp1[1][2] == sbp2[1][2]:\n",
    "            # if left and right breakpoint locations are within d\n",
    "            if (abs(sbp1[0][1] - sbp2[0][1]) + abs(sbp1[1][1] - sbp2[1][1]) < d) or (abs(sbp1[0][1] - sbp2[1][1]) + abs(sbp1[1][1] - sbp2[0][1]) < d):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class Cycle(object):\n",
    "    \n",
    "    def __init__(self,cn,length,breakpoints,circular,trivial):\n",
    "        self.cn=float(cn)\n",
    "        self.length=int(length)\n",
    "        self.breakpoints=breakpoints # list of breakpoints\n",
    "        self.circular=bool(circular)\n",
    "        self.trivial=bool(trivial)\n",
    "        \n",
    "    def __str__(self):\n",
    "        bp_expanded=','.join(str(b) for b in self.breakpoints)\n",
    "        return(f'Copy_count={self.cn};Length={self.length}bp;Breakpoints={bp_expanded};Circular={self.circular};Trivial={self.trivial}')\n",
    "        \n",
    "    def __add__(self,o):\n",
    "        return Cycle(cn=np.mean([self.cn,o.cn]), length=self.length+o.length, breakpoints=self.breakpoints+o.breakpoints,\n",
    "                    circular = self.circular&o.circular, trivial = self.trivial&o.trivial)\n",
    "    \n",
    "    def diff(self,o,d=1000):\n",
    "        df = np.zeros((len(self.breakpoints),len(o.breakpoints)))\n",
    "        for i in range(len(self.breakpoints)):\n",
    "            for j in range(len(o.breakpoints)):\n",
    "                df[i,j]=self.breakpoints[i].d_similar(o.breakpoints[j],d)\n",
    "        return df\n",
    "    \n",
    "    def plot_diff(self,other,d=1000):\n",
    "        df = self.diff(other,d=d)\n",
    "        #plt.imshow(binary_matrix, cmap='viridis', interpolation='nearest')\n",
    "        plt.imshow(df)\n",
    "        # Set x-axis labels\n",
    "        plt.yticks(np.arange(len(self.breakpoints)), map(str,self.breakpoints))\n",
    "\n",
    "        # Set y-axis labels\n",
    "        plt.xticks(np.arange(len(other.breakpoints)), map(str,other.breakpoints), rotation=90)\n",
    "\n",
    "        # Add labels to the axes\n",
    "        plt.ylabel(\"Self\")\n",
    "        plt.xlabel(\"Other\")\n",
    "        \n",
    "        plt.grid(True, which='both', linestyle='-', linewidth=1, color='white')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        \n",
    "class Converted_Cycles(object):\n",
    "    def __init__(self,cycles,segments,intervals):\n",
    "        self.cycles=cycles\n",
    "        self.segments=segments\n",
    "        self.intervals=intervals\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        '''\n",
    "        path or iobuffer to a _BPG_converted_cycles.txt file\n",
    "        '''\n",
    "        self.intervals=[('Source',0,0)] #(chr start end)\n",
    "        self.segments=[('Source',0,0)] #(chr start end)\n",
    "        self.cycles=[] # Cycles\n",
    "        with open(path,'r') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('Interval'):\n",
    "                    self.parse_interval(line)\n",
    "                elif line.startswith('Segment'):\n",
    "                    self.parse_segment(line)\n",
    "                elif line.startswith('Cycle'):\n",
    "                    self.parse_cycle(line)\n",
    "                else:\n",
    "                    continue\n",
    "                        \n",
    "    def parse_segment(self,line):\n",
    "        line=line.strip().split()\n",
    "        self.segments.append((line[2],int(line[3]),int(line[4])))\n",
    "    def parse_interval(self,line):\n",
    "        line=line.strip().split()\n",
    "        self.intervals.append((line[2],int(line[3]),int(line[4])))\n",
    "    def parse_breakpoints(self,subline):\n",
    "        subline=subline.split(',')\n",
    "        breakpoints=[]\n",
    "        for i in range(len(subline)):\n",
    "            c=(int(subline[i][:-1]),subline[i][-1]) #current\n",
    "            n_i = i+1 if i+1 < len(subline) else 0\n",
    "            n=(int(subline[n_i][:-1]),subline[n_i][-1]) #next\n",
    "            if c[1]=='+' and n[1]=='+' and n[0]-c[0]==1:\n",
    "                continue\n",
    "            elif c[1]=='-' and n[1]=='-' and c[0]-n[0]==1:\n",
    "                continue\n",
    "            else:\n",
    "                breakpoints.append(Breakpoint(\n",
    "                    self.segments[c[0]][0],self.segments[c[0]][2] if c[1]=='+' else self.segments[c[0]][1],c[1]=='+',\n",
    "                    self.segments[n[0]][0],self.segments[n[0]][1] if n[1]=='+' else self.segments[n[0]][2],n[1]!='+',\n",
    "                    None\n",
    "                ))\n",
    "        return breakpoints\n",
    "        \n",
    "    def parse_cycle(self,line):\n",
    "        line=list(map(lambda x: x.split('='), line.strip().split(';')))\n",
    "        self.cycles.append(Cycle(cn=line[1][1],\n",
    "                                length=line[2][1][:-2],\n",
    "                                breakpoints=self.parse_breakpoints(line[3][1]),\n",
    "                                circular=line[4][1] == 'TRUE',\n",
    "                                trivial=line[5][1] == 'TRUE'))\n",
    "        \n",
    "        \n",
    "BS_W37QBA12_parse = Converted_Cycles('CycleViz/BS_W37QBA12/BS_W37QBA12_amplicon1_BPG_converted_cycles.txt')\n",
    "BS_2J4FG4HV_parse = Converted_Cycles('CycleViz/BS_2J4FG4HV/BS_2J4FG4HV_amplicon1_BPG_converted_cycles.txt')\n",
    "BS_5JC116NM_parse = Converted_Cycles('CycleViz/BS_5JC116NM/BS_5JC116NM_amplicon1_BPG_converted_cycles.txt')\n",
    "\n",
    "empty=Cycle(np.nan,0,[],True,True)\n",
    "BS_W37QBA12_ecdna = sum(BS_W37QBA12_parse.cycles[:3],empty)\n",
    "BS_2J4FG4HV_ecdna = sum(BS_2J4FG4HV_parse.cycles[:3],empty)\n",
    "BS_5JC116NM_ecdna = sum(BS_5JC116NM_parse.cycles[:6],empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe5c5a-e375-462d-8652-b16061e1cc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SJRHB012_D_parse = Converted_Cycles('CycleViz/SJRHB012_D/SJRHB012_D_amplicon1_BPG_converted_cycles.txt')\n",
    "SJRHB012_R_parse1 = Converted_Cycles('CycleViz/SJRHB012_S/SJRHB012_S_amplicon1_BPG_converted_cycles.txt')\n",
    "SJRHB012_R_parse2 = Converted_Cycles('CycleViz/SJRHB012_S/SJRHB012_S_amplicon2_BPG_converted_cycles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28948b0c-57ee-4a15-904f-9e6d0f2a69b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SJRHB012_D_ecdna1 = SJRHB012_D_parse.cycles[3]\n",
    "SJRHB012_R_ecdna1 = SJRHB012_R_parse1.cycles[0]\n",
    "SJRHB012_D_ecdna2 = SJRHB012_D_parse.cycles[0]\n",
    "SJRHB012_R_ecdna2 = SJRHB012_R_parse2.cycles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c949f-d50a-4ece-8819-0feb2022cb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SJRHB012_D_ecdna1.plot_diff(SJRHB012_R_ecdna1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683f43f-6e41-4fc1-9869-340dcfd0cbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SJRHB012_D_ecdna2.plot_diff(SJRHB012_R_ecdna2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa9045-589d-40d3-a5d0-d6f0c70a8fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# primary vs primary\n",
    "BS_2J4FG4HV_ecdna.plot_diff(BS_W37QBA12_ecdna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16113af3-a4dd-49e1-9495-23d7f888023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary vs relapse\n",
    "BS_2J4FG4HV_ecdna.plot_diff(BS_5JC116NM_ecdna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9c565-9906-44b9-b4d8-b87f5cd9c0b6",
   "metadata": {},
   "source": [
    "# Dead code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c726a-ff2c-4739-94c7-6aaf9898475f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What tumor types do the paired biosamples come from?\n",
    "paired_tumor_types = set(BIOSAMPLES[BIOSAMPLES.patient_id.isin(df.index)].cancer_type.unique())\n",
    "ecDNA_tumor_types = set(BIOSAMPLES[BIOSAMPLES.amplicon_class == 'ecDNA'].cancer_type.unique())\n",
    "paired_set = paired_tumor_types & ecDNA_tumor_types\n",
    "paired_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7efc41-2a35-4c74-b46a-b021898876e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1[\"primary_ecDNA\"] = df1.aggregated_value > 0\n",
    "df1.set_index(\"patient_id\",inplace=True)\n",
    "df1.drop(\"aggregated_value\",axis=1,inplace=True)\n",
    "a = len(df1[df1.primary_ecDNA])\n",
    "b = len(df1)\n",
    "print(f\"{a} of {b} ({round(a/b*100,1)}%) primary tumors have ecDNA\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6481533-7434-488b-bba1-0300f1325325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1[\"has_secondary\"] = df1.index.isin(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f2c07-6538-4088-a137-0c5945a023d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a= pd.crosstab(df1.primary_ecDNA, df1.has_secondary)\n",
    "print(a)\n",
    "scipy.stats.chi2_contingency(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04a12e-8b6c-4097-964b-5a8e9567b796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.primary_ecDNA, df.secondary_ecDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51051ac-ef25-4531-8cf5-249feb1cf16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c684cb7-c5b4-4af2-9abf-3bdfc99bd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sj_survival_data(path=\"../data/local/sjcloud/SJ_SurvivalMaster.xlsx\"):\n",
    "    path = pathlib.Path(path)\n",
    "    df = pd.read_excel(path,index_col=0)\n",
    "    return df\n",
    "def clean_sj_survival_data(df):\n",
    "    df = df.dropna(subset=['Date of Primary Dx']).copy()\n",
    "    df['tmp']=df['Date of Death'].fillna(df['Date of data collection'])\n",
    "    df['OS_months'] = (df.tmp - df['Date of Primary Dx']).apply(lambda x:x.days * 12 / 365.25)\n",
    "    df = df.rename(columns={\n",
    "        'Survival Status':'OS_status'\n",
    "    })\n",
    "    df = df[['OS_status','OS_months']]\n",
    "    df = df.replace({\n",
    "        'OS_status':{\n",
    "            \"Expired\": \"Deceased\",\n",
    "        }\n",
    "    })\n",
    "    return df\n",
    "def import_clean_cbtn_survival_data():\n",
    "    df = generate_cbtn_biosample_table(verbose=1)\n",
    "    df['OS_months']=df['OS_days']*12/365.25\n",
    "    df = df[['OS_status','OS_months']]\n",
    "    df = df.replace({\n",
    "        'OS_status':{\n",
    "            \"DECEASED\": \"Deceased\",\n",
    "            \"LIVING\":\"Alive\",\n",
    "        }\n",
    "    })\n",
    "    return df\n",
    "    \n",
    "def generate_patient_table():\n",
    "    # Start with biosamples\n",
    "    df = generate_biosample_table()\n",
    "    df = df[df.in_unique_patient_set == True]\n",
    "    df = df[['sex','patient_id','age_at_diagnosis','cohort','cancer_type','amplicon_class']]\n",
    "    # Add sj survival data\n",
    "    surv = import_sj_survival_data()\n",
    "    surv = clean_sj_survival_data(surv)\n",
    "    # Add cbtn survival data\n",
    "    surv = pd.concat([surv,import_clean_cbtn_survival_data()])\n",
    "    df = df.join(surv)\n",
    "    df.set_index('patient_id')\n",
    "    return df\n",
    "\n",
    "df = generate_patient_table()\n",
    "df.tail(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e989f6-708d-4b7a-9ece-cd0d4dfa4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857605a-a02b-46f9-9677-d7a923855bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72074bd7-be00-4c07-a313-20ba310f7372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aae832-b030-46ff-9565-c3b32779db17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1c54e-101a-4385-81e3-b7d47070eb1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdc86f-5907-41a7-9b6f-5524374e549e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df.subject_name.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18584d7-3cfa-4984-a3bf-3c4a00aa9cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df2))\n",
    "print(len(df2[\"Kids First Participant ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686a8db-1916-4b76-894c-450bd2b445dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df2['Tumor Descriptor'].unique())\n",
    "print(df.sample_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed385e-6501-4179-bf6b-687df58c0484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_pedcbioportal_metadata(path=\"../2023-11-27_cavatica-api/out/openpbta-biosample-metadata.tsv\"):\n",
    "    path = pathlib.Path(path)\n",
    "    df = pd.read_csv(path, sep='\\t',index_col=0)\n",
    "    return df\n",
    "def get_cbtn_cell_lines():\n",
    "    df = import_pedcbioportal_metadata()\n",
    "    df = df[df.SAMPLE_TYPE == \"Derived Cell Line\"]\n",
    "    return df.SPECIMEN_ID.str.cat(sep=';').split(';')\n",
    "#get_cbtn_cell_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca71a4a-c675-448f-9fcc-81ba8843c03c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbtn_pairs = df2[df2.in_deduplicated_sample_cohort]\n",
    "cbtn_pairs = cbtn_pairs[cbtn_pairs[\"Tumor Descriptor\"] != \"Second Malignancy\"]\n",
    "cbtn_pairs = cbtn_pairs[cbtn_pairs[\"Kids First Participant ID\"].duplicated(keep=False)].sort_values(\"Kids First Participant ID\")\n",
    "print(len(cbtn_pairs[\"Kids First Participant ID\"].unique()))\n",
    "#cbtn_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e62b75-59d0-4c02-8b25-fbed56de9ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e47192-725f-4025-9b04-4ede1d972fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = df[df.in_deduplicated_sample_cohort]\n",
    "pairs = pairs[pairs.subject_name.duplicated(keep=False)].sort_values('subject_name')\n",
    "pairs = pairs[~pairs.subject_name.isin([\"SJ030303\",\"SJ030890\"])] # these patients had multiple primaries of different histologies.\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfac11b-5d75-45cc-9f58-fcb13ea5cdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all patients with more than one sample.\n",
    "sj_dups = df[df.subject_name.duplicated(keep=False)].sort_values('subject_name')\n",
    "print(len(sj_dups.subject_name.unique()))\n",
    "#sj_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571a598-af13-4b26-a89d-8c9e63061cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weirdly, there are 10 biosamples not in Sunita's paired samples table. Some, but not all, are true duplicates.\n",
    "def import_sunita_sj_master_table(path=\"/Users/ochapman/Library/CloudStorage/OneDrive-SanfordBurnhamPrebysMedicalDiscoveryInstitute/projects/2023-pedpancan/data/PedPanCancer_StJude_MasterAnalysis_Copy.xlsx\"):\n",
    "    path=pathlib.Path(path)\n",
    "    df = pd.read_excel(path,index_col=0,sheet_name='PairedSamples')\n",
    "    return df\n",
    "sunita = import_sunita_sj_master_table()\n",
    "missing = set(dups.subject_name.unique())-set(sunita.index.unique())\n",
    "print(len(missing))\n",
    "#dups[dups.subject_name.isin(missing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7364f5d-c3e6-4bca-9c4b-dfe195db95e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184aea7-ed91-4d5d-8713-6ad6636134c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d170908-b693-43c0-9f85-eefbfbf6d0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
